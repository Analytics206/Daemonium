# Daemonium
---
## Version 0.3.23 (August 22, 2025)

### Backend: Idea Summaries ‚Äî Keywords Field Support and Filtering

- Added `keywords: string[]` to `IdeaSummary` in `backend/models.py` so responses include the `keywords` array when present.
- `GET /api/v1/ideas/summaries` now accepts optional `keyword` and filters in-memory against the `keywords` list (case-insensitive substring match). Response uses `IdeaSummary`, ensuring `keywords` is serialized.
- `GET /api/v1/summaries/search/idea_summary?query=...` includes `keywords` in the `$or` regex filter alongside `author`, `category`, `title`, `quote`, `summary.section`, `summary.content`, and `key_books`.
- `GET /api/v1/ideas/search/{keyword}` also searches `keywords` in MongoDB for idea summaries.
- Backward compatibility: `philosopher` query param is supported and mapped to `author` for filtering; responses normalize to `author`.

### Files Changed

- `backend/models.py`
- `docs/06-system_design.md` ‚Äî added Idea Summaries keywords section
- `docs/12-release_notes.md` ‚Äî this entry

### Verification (PowerShell)

```powershell
$base = 'http://localhost:8000'

# 1) Baseline: list idea summaries; expect items to include keywords when present
Invoke-RestMethod -Method Get -Uri "$base/api/v1/ideas/summaries?limit=5"

# 2) Filter by keyword (case-insensitive substring against keywords array)
Invoke-RestMethod -Method Get -Uri "$base/api/v1/ideas/summaries?keyword=virtue&limit=5"

# 3) Inspect keywords from the first item
$resp = Invoke-RestMethod -Method Get -Uri "$base/api/v1/ideas/summaries?limit=3"
($resp.data | Select-Object -First 1) | ForEach-Object { $_.title; $_.keywords }

# 4) Search routes also include keywords
Invoke-RestMethod -Method Get -Uri "$base/api/v1/ideas/search/virtue"
Invoke-RestMethod -Method Get -Uri "$base/api/v1/summaries/search/idea_summary?query=virtue&limit=5"
```

---
## Version 0.3.22 (August 21, 2025)

### Backend: Aphorisms ‚Äî Nested Subject Schema Cleanup and Tests

- Fully aligned aphorisms search and indexing with nested `subject.*` schema; removed usage of legacy top-level fields `themes` and `text` from queries and indexes.
- `backend/routers/aphorisms.py`:
  - `GET /api/v1/aphorisms/` accepts `subject_theme`, `subject_keyword`, `subject_aphorism` and forwards them to the DB layer.
  - `GET /api/v1/aphorisms/by-theme/{theme}` uses `$or` across `subject.theme` and `context`.
  - `GET /api/v1/aphorisms/{keyword}` uses `$or` across `author`, `philosopher` (alias), `category`, `context`, and nested `subject.theme|subject.keywords|subject.aphorisms`.
- `backend/routers/search.py` and `backend/database.py` ensure filters target nested `subject.*` fields only; drop any legacy top-level `themes` index if present.
- Backward compatibility: `philosopher` query param remains accepted and mapped to `author` for filtering.

### Tests

- `tests/test_aphorisms_nested_subjects.py` verifies nested-field usage and DB passthrough:
  - Filters by `subject_theme`, `subject_keyword`, `subject_aphorism`, and combinations with `philosopher`.
  - Keyword and theme routes assert `$or` includes `subject.theme`, `subject.keywords`, `subject.aphorisms`.
  - No-result case returns `data: []` with `total_count: 0`.

### Verification (PowerShell)

```powershell
$base = 'http://localhost:8000'

# Main list with nested filters
Invoke-RestMethod -Method Get -Uri "$base/api/v1/aphorisms/?subject_theme=Ethics&limit=5"
Invoke-RestMethod -Method Get -Uri "$base/api/v1/aphorisms/?subject_keyword=virtue&limit=5"
Invoke-RestMethod -Method Get -Uri "$base/api/v1/aphorisms/?subject_aphorism=Custom&limit=5"

# Theme and keyword routes
Invoke-RestMethod -Method Get -Uri "$base/api/v1/aphorisms/by-theme/Ethics?limit=5"
Invoke-RestMethod -Method Get -Uri "$base/api/v1/aphorisms/virtue?limit=5"
```

### Files Changed

- `backend/routers/aphorisms.py`
- `backend/routers/search.py`
- `backend/database.py`
- `docs/06-system_design.md` ‚Äî updated with "Aphorisms Schema Cleanup ‚Äî Legacy Field Removal (v0.3.22)"
- `docs/12-release_notes.md` ‚Äî this entry

---
## Version 0.3.21 (August 21, 2025)

### Backend: Aphorisms ‚Äî Ingestion v2, Nested Structure, and Index Verification

- Preserved nested `subject` structure from source JSON with normalized arrays and removed legacy top-level `keywords`/`aphorisms`.
- Uploader `scripts/build_mongodb_metadata/upload_aphorisms_to_mongodb.py` (v2.0.0) creates indexes:
  - Single-field: `idx_author`, `idx_filename`, `idx_category`.
  - Nested: `idx_subject_theme` (on `subject.theme`), `idx_subject_keywords` (on `subject.keywords`), `idx_subject_aphorisms` (on `subject.aphorisms`).
  - Unified text index: `aphorisms_text_index` over `author`, `category`, `subject.theme`, `subject.keywords`, `subject.aphorisms` (drops any existing text indexes first to ensure only one exists on the collection).
- Added verification script `scripts/build_mongodb_metadata/verify_aphorisms_indexes.py` to validate index presence/shape, confirm nested document structure, and run smoke queries for nested membership and `$text` search.
- System design updated with a dedicated section documenting ingestion v2 and indexing.

### Files Changed

- `scripts/build_mongodb_metadata/verify_aphorisms_indexes.py` ‚Äî new script
- `docs/06-system_design.md` ‚Äî added "Backend: Aphorisms Ingestion v2" section
- `docs/12-release_notes.md` ‚Äî this entry

### Verification (PowerShell)

```powershell
# From project root with your venv active

# 1) Upload/update aphorisms
python scripts/build_mongodb_metadata/upload_aphorisms_to_mongodb.py

# 2) Verify indexes, nested structure, and run smoke tests
python scripts/build_mongodb_metadata/verify_aphorisms_indexes.py
```

---
## Version 0.3.20 (August 20, 2025)

### Backend: Discussion Hooks ‚Äî Index Verification Script

- Added verification script for MongoDB `discussion_hook` collection indexes and smoke tests.
- Ensures single-field indexes exist and a single compound text index `discussion_hooks_text_v2` is present over nested fields.
- Loads MongoDB settings from `config/default.yaml`; exits with code 0 on success, 1 on failure.

### Files Changed

- `scripts/build_mongodb_metadata/verify_discussion_hook_indexes.py` ‚Äî new script
- `docs/06-system_design.md` ‚Äî added "Backend: Discussion Hooks Indexes & Verification" section
- `docs/12-release_notes.md` ‚Äî this entry

### Verification (PowerShell)

```powershell
# From project root with your venv active
python scripts/build_mongodb_metadata/verify_discussion_hook_indexes.py
```

---
## Version 0.3.19 (August 20, 2025)

### Backend: Bibliography ‚Äî Keywords in Works + Legacy Field Removal

- Added `keywords: string[]` to `BibliographyWork` in `backend/models.py` to align with uploader v2 JSON.
- Removed legacy `original_key` from `Bibliography` in `backend/models.py`.
- API endpoints automatically serialize `works[].keywords` when present; unknown legacy fields from DB are ignored.

### Files Changed

- `backend/models.py`
- `docs/06-system_design.md` ‚Äî documented schema and behavior
- `docs/12-release_notes.md` ‚Äî this entry

### Verification (PowerShell)

```powershell
$base = 'http://localhost:8000'

# 1) List bibliographies (expect data with works; keywords appear when present per work)
Invoke-RestMethod -Method Get -Uri "$base/api/v1/books/bibliography?limit=3"

# 2) By author
Invoke-RestMethod -Method Get -Uri "$base/api/v1/books/bibliography/by-author/Friedrich%20Wilhelm%20Nietzsche"

# 3) Inspect first few works' titles and keywords
$resp = Invoke-RestMethod -Method Get -Uri "$base/api/v1/books/bibliography/by-author/Friedrich%20Wilhelm%20Nietzsche"
($resp.data.works | Select-Object -First 3) | ForEach-Object { $_.title; $_.keywords }
```

---
## Version 0.3.18 (August 20, 2025)

### Backend: Global Search includes Philosophy Keywords + Verification Script

- Added `philosophy_keywords` to global search scope in `backend/database.py` and API router `backend/routers/search.py`.
- Implemented collection-specific regex filter for `philosophy_keywords` supporting fields: `theme`, `definition`, `keywords`.
- Ensures index alignment with ingestion v2: single text index `philosophy_keywords_text_v2` over `theme/definition/keywords`.

### Files Changed

- `backend/database.py` ‚Äî global search includes `philosophy_keywords` with proper filter.
- `backend/routers/search.py` ‚Äî valid collections updated; added `philosophy_keywords` filter.
- `docs/06-system_design.md` ‚Äî updated global search coverage.
- `docs/12-release_notes.md` ‚Äî this entry.
- `scripts/build_mongodb_metadata/verify_philosophy_keywords_indexes.py` ‚Äî new verification script ensuring index presence and smoke tests.

### Verification (PowerShell)

```powershell
$base = 'http://localhost:8000'

# 1) Global search should now include philosophy_keywords
Invoke-RestMethod -Method Get -Uri "$base/api/v1/search?query=ethics"

# 2) Filtered to philosophy_keywords only
Invoke-RestMethod -Method Get -Uri "$base/api/v1/search?query=ethics&collections=philosophy_keywords"

# 3) Multiple collections filter (philosophy_keywords + philosophy_schools)
Invoke-RestMethod -Method Get -Uri "$base/api/v1/search?query=ethics&collections=philosophy_keywords,philosophy_schools"

# 4) Direct summaries search for philosophy_keywords (existing)
Invoke-RestMethod -Method Get -Uri "$base/api/v1/summaries/search/philosophy_keywords?query=ethics&limit=5"

# 5) Run verification script for philosophy_keywords indexes
python scripts/build_mongodb_metadata/verify_philosophy_keywords_indexes.py
```

---
## Version 0.3.17 (August 20, 2025)

### Backend: Summaries ‚Äî Philosophy Keywords API + Search Integration

- Added new endpoint `/api/v1/summaries/philosophy-keywords` serving paginated data from MongoDB collection `philosophy_keywords`.
- Response model aligns with other summary endpoints using `PhilosophyKeywordResponse` and `PhilosophyKeyword`.
- Database layer adds `get_philosophy_keywords(skip, limit)` and ensures `_id` is stringified.
- Included `philosophy_keywords` in generic summaries routes:
  - `GET /api/v1/summaries/by-collection/philosophy_keywords`
  - `GET /api/v1/summaries/search/philosophy_keywords?query=...` (matches `theme`, `definition`, `keywords`).

### Files Changed

- `backend/models.py` ‚Äî added `PhilosophyKeyword` and `PhilosophyKeywordResponse`.
- `backend/database.py` ‚Äî registered collection and added `get_philosophy_keywords()`.
- `backend/routers/summaries.py` ‚Äî new route `/philosophy-keywords`; added `philosophy_keywords` to valid collections for by-collection and search.
- `docs/06-system_design.md` ‚Äî documented the new API section.
- `docs/12-release_notes.md` ‚Äî this entry.

### Verification (PowerShell)

```powershell
$base = 'http://localhost:8000'

# 1) Fetch paginated philosophy keywords
Invoke-RestMethod -Method Get -Uri "$base/api/v1/summaries/philosophy-keywords?skip=0&limit=20"

# 2) Generic by-collection access
Invoke-RestMethod -Method Get -Uri "$base/api/v1/summaries/by-collection/philosophy_keywords?limit=5"

# 3) Search within philosophy_keywords (theme/definition/keywords)
Invoke-RestMethod -Method Get -Uri "$base/api/v1/summaries/search/philosophy_keywords?query=ethics&limit=5"
```

---
## Version 0.3.16 (August 20, 2025)

### Backend: Global Search includes Philosophy Schools + Collection Naming Fix

- Added `philosophy_schools` to global search scope in `backend/database.py` and API router `backend/routers/search.py`.
- Implemented collection-specific regex filter for `philosophy_schools` supporting fields: `name`, `school`, `category`, `summary`, `core_principles`, `corePrinciples`, and `keywords`.
- Corrected collection name references from `top_ten_ideas` to `top_10_ideas` across the search router to match database naming.

### Files Changed

- `backend/database.py` ‚Äî global search now includes `philosophy_schools` with keywords support.
- `backend/routers/search.py` ‚Äî valid collections updated; added `philosophy_schools` filter; fixed `top_10_ideas` naming.

### Verification (PowerShell)

```powershell
$base = 'http://localhost:8000'

# Global search (all collections)
Invoke-RestMethod -Method Get -Uri "$base/api/v1/search?query=stoic"

# Filtered to philosophy_schools only
Invoke-RestMethod -Method Get -Uri "$base/api/v1/search?query=logos&collections=philosophy_schools"

# Content-only search (books, book_summary, aphorisms, top_10_ideas, idea_summary)
Invoke-RestMethod -Method Get -Uri "$base/api/v1/search/content?query=virtue"
```

---
## Version 0.3.15 (August 19, 2025)

### Data Ingestion: Philosophy Schools Keywords v2 + Uploader v2.0.0

- Adopted explicit `keywords: string[]` in `json_bot_docs/philosophy_school/philosophy_school.json` (used directly; no legacy derivation).
- Updated uploader `scripts/build_mongodb_metadata/upload_philosophy_schools_to_mongodb.py` to v2.0.0:
  - Uses provided `keywords` array with normalization (trim, case-insensitive dedup, order preserved).
  - Removes legacy keyword extraction from `summary` and `corePrinciples`.
  - Creates indexes: `school_id` (unique), `school`, `category`, `school+category`, `keywords`.
  - Drops any existing text index then creates a single text index over `school/summary/core_principles/keywords`.
  - Adds derived fields: `school_normalized`, `category_normalized`.

### Files Changed

- `scripts/build_mongodb_metadata/upload_philosophy_schools_to_mongodb.py` (Version 2.0.0)
- `docs/06-system_design.md` ‚Äî added "Philosophy Schools Ingestion v2" section
- `docs/12-release_notes.md` ‚Äî this entry

### Verification (PowerShell)

```powershell
# From project root with venv active
python scripts/build_mongodb_metadata/upload_philosophy_schools_to_mongodb.py

# After run, verify MongoDB collection 'philosophy_schools' has documents with 'keywords' arrays populated
# Optionally verify indexes via your MongoDB client (one text index named 'philosophy_schools_text_v2')
```

---
## Version 0.3.14 (August 19, 2025)

### Data Ingestion: Philosophy Keywords JSON Restructure + Uploader v2.0.0

- Simplified `json_bot_docs/philosophy_keywords/philosophy_keywords.json` to a flat JSON array of entries:
  - `{ theme: string, definition: string, keywords: string[] }`
- Updated uploader `scripts/build_mongodb_metadata/upload_philosophy_keywords_to_mongodb.py` to v2.0.0:
  - Processes the new array format only (legacy formats removed)
  - Upserts one document per theme into `philosophy_keywords` (Mongo `_id` = slugified `theme`)
  - Indexes: `theme`, `filename`, `keywords`, and a text index over `theme/definition/keywords`
  - Deduplicates/normalizes keyword strings per entry
- Collection shape change is localized; no other services referenced legacy fields.

### Verification (PowerShell)

```powershell
# From project root with your venv active
python scripts/build_mongodb_metadata/upload_philosophy_keywords_to_mongodb.py

# After run, verify documents per theme exist in MongoDB collection 'philosophy_keywords'
# (e.g., via mongosh or your preferred MongoDB client)
```

---
## Version 0.3.13 (August 19, 2025)

### Web UI + API: Ollama response capture fixed and Redis logging centralized (UID-only, no duplicates)

- Enforced Firebase UID-only identity across chat UI for all backend calls and Redis keys.
- Removed duplicate `assistant_message` push from `web-ui/src/components/chat/chat-interface.tsx`; UI now only pushes `session_start`, `user_message`, and `session_end`.
- Centralized assistant message persistence inside the Next.js Ollama API route (`web-ui/src/app/api/ollama/route.ts`):
  - Normalizes Ollama responses to `{ response: string }` for the UI.
  - Fire-and-forget pushes `assistant_message` payload to the FastAPI Redis endpoint with proper Authorization headers.
  - Prevents duplicate assistant entries by making the API route the single source of truth.
- Consistent Redis keying by UID ensures recents/history load correctly per authenticated user.

### Files Changed

- `web-ui/src/components/chat/chat-page-container.tsx`
- `web-ui/src/components/chat/chat-interface.tsx`
- `web-ui/src/app/api/ollama/route.ts`
- `docs/06-system_design.md`
- `docs/12-release_notes.md`

### Verification (PowerShell)

```powershell
# Prereqs: web-ui dev server and backend running; obtain a Firebase ID token into $token
$web = 'http://localhost:3000'
$base = 'http://localhost:8000'
$u = '<firebase_uid>'
$c = '<chatId>'  # Use the ChatID shown in the browser console or UI
$token = '<paste_firebase_id_token>'

# Send a prompt through the Next.js API route (server proxies to Ollama and pushes assistant_message to backend)
$body = @{ message='Hello Ollama'; chatId=$c; userId=$u; philosopher='Local LLM' } | ConvertTo-Json -Depth 5
Invoke-RestMethod -Method Post -Headers @{ 'Content-Type'='application/json'; Authorization = "Bearer $token" } -Uri "$web/api/ollama" -Body $body

# Verify Redis now has exactly one assistant_message for this turn
Invoke-RestMethod -Method Get -Headers @{ Authorization = "Bearer $token" } -Uri "$base/api/v1/chat/redis/$($u)/$($c)"
```

---
## Version 0.3.12 (August 19, 2025)

### Backend: Firebase ID Token Validation for Redis Chat Endpoints

- Added secure Firebase ID token verification and per-user authorization to FastAPI Redis chat APIs.
- Initializes Firebase Admin SDK on app startup; robust error handling and logging without exposing secrets.
- Enforces that token UID matches `user_id` in path params; returns appropriate HTTP errors on failure.

### Files Changed

- `backend/auth.py` ‚Äî new module: Firebase Admin init + `verify_firebase_id_token` dependency
- `backend/main.py` ‚Äî lifespan startup initializes Firebase Admin if enabled
- `backend/routers/chat.py` ‚Äî applied auth dependency to Redis chat endpoints with `user_id`
- `backend/config.py` ‚Äî added Firebase settings with env overrides
- `config/default.yaml` ‚Äî new `firebase` section with credentials options
- `docs/06-system_design.md` ‚Äî architecture and verification steps for backend token validation
- `docs/07-tech_stack.md` ‚Äî tech stack section for backend Firebase Admin
- `docs/12-release_notes.md` ‚Äî this entry

### Configuration

- YAML (`config/default.yaml`):
  - `firebase.enabled` (bool)
  - `firebase.project_id` (string)
  - `firebase.credentials.file` (path) or `firebase.credentials.base64` (base64 JSON)
- Environment overrides:
  - `FIREBASE_ENABLED`, `FIREBASE_PROJECT_ID`, `FIREBASE_CREDENTIALS_FILE`, `FIREBASE_CREDENTIALS_BASE64`
- Dependency: `firebase-admin>=6.5.0` in `requirements.txt`

### Verification (PowerShell)

```powershell
$base = 'http://localhost:8000'
$u = '<firebase_uid>'
$c = '<chatId>'
$token = '<paste_firebase_id_token>'

# GET chat history (requires valid token; UID must match $u)
Invoke-RestMethod -Method Get -Headers @{ Authorization = "Bearer $token" } -Uri "$base/api/v1/chat/redis/$($u)/$($c)"

# POST a message (JSON payload via query param)
$payload = @{ type='user_message'; text='Hello from release test' } | ConvertTo-Json -Depth 5
$enc = [System.Web.HttpUtility]::UrlEncode($payload)
Invoke-RestMethod -Method Post -Headers @{ Authorization = "Bearer $token" } -Uri "$base/api/v1/chat/redis/$($u)/$($c)?input=$enc&ttl_seconds=0"
```

### Notes

- If Firebase is disabled, the dependency is a no-op for backward compatibility.
- Initialization failures are logged and cause the dependency to return 503 without crashing startup.

---
## Version 0.3.11 (August 19, 2025)

### Web UI: Ollama API Proxy Reliability

- Improved Ollama base URL resolution in `web-ui/src/app/api/ollama/route.ts`:
  - Honors `OLLAMA_BASE_URL` and legacy `OLLAMA_API_URL`/`OLLAMA_API_PORT`.
  - Uses IPv4 loopback for explicit `localhost` to avoid IPv6 issues on Windows.
  - Adds fallback to `http://host.docker.internal:11434` whenever an initial loopback attempt fails (more robust inside Docker containers).
- Aligned default model to `llama3.1:latest`:
  - Route default updated in `route.ts`.
  - Compose default updated in `docker-compose.yml` under `web-ui` service env `OLLAMA_MODEL`.

### Files Changed

- `web-ui/src/app/api/ollama/route.ts`
- `docker-compose.yml`

---
## Version 0.3.10-p1 (August 19, 2025)

### Web UI: Firebase Auth Robustness Patches

- Replaced unsafe `auth` references with reconstructed instances via `getAuth()`:
  - `web-ui/src/components/providers/firebase-auth-provider.tsx` now obtains a local `Auth` for `onAuthStateChanged()` and `signOut()`.
  - `web-ui/src/components/auth/login-form.tsx` uses a local `Auth` for `getRedirectResult()` and `signInWithEmailAndPassword()`.
  - `web-ui/src/components/auth/register-form.tsx` uses a local `Auth` for `createUserWithEmailAndPassword()` and `updateProfile()`.
- Removed immediate `router.replace()` after `signInWithGoogle()`; navigation is now handled by auth state changes and redirect result flow to avoid conflicts with redirect fallback.
- Eliminated brittle `hasAuth` checks causing TS narrowing issues; added guarded try/catch around `getAuth()` usage when Firebase config is missing.

### Developer Notes

- These changes further mitigate `auth/argument-error` by avoiding undefined `auth` instances and race conditions between popup and redirect flows. TypeScript errors about possibly undefined `auth` are resolved by local reconstruction.

---
## Version 0.3.10 (August 19, 2025)

### Web UI: Firebase Google Sign-In Reliability & Redirect Handling

- Persist intended destination across Google sign-in redirect in `web-ui/src/components/auth/login-form.tsx`:
  - Store `returnTo` in `sessionStorage` under `auth_return_to` before calling Google sign-in
  - After auth, auto-route to stored destination and clear the key
- Surface redirect errors on page load by calling `getRedirectResult(auth)` on mount (guarded when Firebase auth is not initialized) to display user-friendly messages (e.g., unauthorized-domain, operation-not-allowed)
- Improve popup fallback in `web-ui/src/components/providers/firebase-auth-provider.tsx`:
  - Now falls back to `signInWithRedirect` for additional cases including `auth/operation-not-supported-in-this-environment`
- UX improvement: Keep "Continue with Google" enabled during initial Firebase load; only disable during an active attempt to avoid dead clicks

### Configuration Checklist

- Firebase Console ‚Üí Authentication ‚Üí Sign-in method: enable Google provider
- Firebase Console ‚Üí Authentication ‚Üí Settings ‚Üí Authorized domains: include `localhost` and `127.0.0.1`
- Ensure `NEXT_PUBLIC_FIREBASE_*` variables are present at build and runtime (Compose and Dockerfile already propagate them)

### Verification

- Dev: from `web-ui/` run `npm run dev`, open `http://localhost:3000/login`, click "Continue with Google"
- Expect either a popup or automatic redirect flow. On success, you will be routed to `returnTo` (or `/chat` by default)
- If errors occur, a descriptive message appears under the form (e.g., popup blocked, unauthorized domain)

## Version 0.3.9 (August 18, 2025)

### Web UI: Restore Philosopher Images and Docker Build Stability

- Restored static philosopher images in `web-ui/public/images/`:
  - `socrates.png` (copied from `philosophers/Plato/images/Socrates-00.png`)
  - `nietzsche.png` (copied from `philosophers/Nietzsche/Nietzsche - Human, All-Too-Human Part 2/Nietzsche - Human, All-Too-Human Part 2.png`)
- Updated `web-ui/src/components/sections/featured-philosophers.tsx` to:
  - Use Next.js `Image` with graceful fallback avatar when image missing
  - Reference `socrates.png` and `nietzsche.png` under `/images/`
  - Leave missing assets undefined to avoid 404s and hydration issues
- Verified Docker Compose `web-ui` build-time args and runtime env:
  - Build args inline `NEXT_PUBLIC_*` Firebase and `NEXT_PUBLIC_BACKEND_API_URL`
  - Runtime env sets `BACKEND_API_URL=http://backend:8000` (server-side) and `NEXT_PUBLIC_BACKEND_API_URL=http://localhost:8000` (browser)
- Confirmed health route `web-ui/src/app/api/health/route.ts` used by Docker healthcheck `/api/health`.
- Audited Suspense usage: present only around auth forms (`/login`, `/register`) with safe fallbacks; no SSR/hydration regressions observed.

### Verification

- Local build (PowerShell):
  - From `web-ui/`: `npm ci` then `npm run build`
  - Visit `http://localhost:3000` (dev: `npm run dev`) and confirm Socrates/Nietzsche images render without 404.
- Docker build/run:
  - `docker compose build web-ui`
  - `docker compose up -d backend web-ui`
  - Health check: `Invoke-RestMethod http://localhost:3000/api/health`
  - UI check: open landing page and verify images + no hydration errors in console.

## Version 0.3.8 (August 18, 2025)

### Web UI: Remove NextAuth, Adopt Firebase-Only Authentication

- Fully removed all runtime usage of NextAuth in `web-ui/`.
- Legacy NextAuth API route `web-ui/src/app/api/auth/[...nextauth]/route.ts` now returns HTTP 410 Gone with guidance to use Firebase Authentication.
- Deprecated environment variables related to NextAuth in `web-ui/.env` and `web-ui/.env.example` (commented out with clear notes):
  - `NEXTAUTH_URL`, `NEXTAUTH_SECRET`, `GOOGLE_CLIENT_ID`, `GOOGLE_CLIENT_SECRET`.
- Firebase Authentication with Google Sign-In is the sole supported auth mechanism.
- Updated documentation to reflect the migration:
  - `docs/web-ui-readme.md`: Authentication strategy and environment variables updated to Firebase-only.
  - This file: added migration notes and deprecation details.

### Configuration

- Firebase env vars required (browser-exposed):
  - `NEXT_PUBLIC_FIREBASE_API_KEY`
  - `NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN`
  - `NEXT_PUBLIC_FIREBASE_PROJECT_ID`
  - `NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET`
  - `NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID`
  - `NEXT_PUBLIC_FIREBASE_APP_ID`
  - `NEXT_PUBLIC_FIREBASE_MEASUREMENT_ID`
- Backend base URL remains `NEXT_PUBLIC_BACKEND_API_URL`.

### Migration Notes

- If you previously configured NextAuth, remove any now-unused secrets from the environment and dashboards.
- Calls to `/api/auth/[...nextauth]` will return 410 Gone. Update clients to use Firebase client-side login via `FirebaseAuthProvider` in `web-ui/src/components/providers/firebase-auth-provider.tsx` and initialization in `web-ui/src/lib/firebase.ts`.
- Clean build output to ensure no lingering artifacts:
  - Remove `.next` and rebuild the app.
  - Optionally run `npm prune` to remove unused packages (no `next-auth` dependency remains in `package.json`).

### Verification

- Confirm no `next-auth` imports exist under `web-ui/src/`.
- Ensure login works via Google Sign-In and user state appears from Firebase (`useFirebaseAuth()`).

## Version 0.3.7 (August 18, 2025)

### Web UI: Firebase Authentication (Google Sign-In)

- Implemented Firebase Authentication in the web UI with Google Sign-In.
- Added `FirebaseAuthProvider` and `useFirebaseAuth()` context with `{ user, loading, signInWithGoogle, signOutUser }`.
- Replaced placeholder chat `userId` with authenticated `user.uid` (preferred) or `user.email`.
- Gated chat UI on auth state: show loading while `loading===true`, show sign-in prompt when unauthenticated.
- Session lifecycle now uses authenticated identity for all Redis events (`session_start`, `user_message`, `assistant_message`, `session_end`).
- Redis POST/GET calls execute only when both `userId` and `chatId` are present.
- Redirect-to-login flow: unauthenticated users are routed to `/login?returnTo=/chat` from the chat UI. `ChatInterface` redirects on send attempt, and the sign-in prompt now links to the dedicated login page using Next.js router with `returnTo`. `ChatPageContainer` uses the authenticated user for fetching recents and disables the recents button when not signed in.

### Environment & Config

- Frontend `.env.example` includes `NEXT_PUBLIC_FIREBASE_*` variables used by `web-ui/src/lib/firebase.ts`.
- `web-ui/src/app/layout.tsx` wraps the app with `FirebaseAuthProvider`.
- Backend base URL continues via `NEXT_PUBLIC_BACKEND_API_URL` (default `http://localhost:8000`).

### Documentation

- Updated `docs/06-system_design.md` to reflect Firebase auth and chat identity changes.
- Updated `docs/07-tech_stack.md` to include Firebase Authentication in the frontend stack.

### Compatibility & Security

- No breaking changes: existing NextAuth credential flow remains.
- Only safe-to-expose Firebase config values are sent to the browser. Backend token verification is a future enhancement.

### Verification (PowerShell)

```powershell
$u = '<firebase_uid_or_email>'
$c = '<chatId from browser console>'
Invoke-RestMethod -Method Get -Uri "http://localhost:8000/api/v1/chat/redis/$($u)/$($c)"
```

### Notes

- This release replaces earlier examples that used `'analytics206@gmail'` as a placeholder. Historical entries remain unchanged.

## Version 0.3.6 (August 17, 2025)

### Backend: Assistant Response History (non-blocking)

- Assistant messages (`type: 'assistant_message'`) are now persisted asynchronously to MongoDB collection `chat_reponse_history`.
- Updated `backend/routers/chat.py` to route background inserts based on message type:
  - Assistant ‚Üí `chat_reponse_history`
  - All others (user/session) ‚Üí `chat_history`
- Reuses the normalized Redis payload and adds `redis_key` for traceability. Failures are logged; HTTP response remains successful.

### Files Changed
- `backend/routers/chat.py` ‚Äî conditional background insert target based on `type`.
- `backend/database.py` ‚Äî ensured `chat_reponse_history` collection is registered.

### Verification (PowerShell)
```powershell
$u = 'analytics206@gmail'
$c = [guid]::NewGuid().ToString()
$assistant = @{ type='assistant_message'; text='Hello from assistant'; model='llama3:latest'; source='ollama' } | ConvertTo-Json -Depth 5
$enc = [System.Web.HttpUtility]::UrlEncode($assistant)
Invoke-RestMethod -Method Post -Uri "http://localhost:8000/api/v1/chat/redis/$($u)/$($c)?input=$enc"
# Optionally fetch Redis to confirm insertion
Invoke-RestMethod -Method Get  -Uri "http://localhost:8000/api/v1/chat/redis/$($u)/$($c)"
```
Then verify the MongoDB document appears in `chat_reponse_history` shortly after.

## Version 0.3.5 (August 17, 2025)

### Backend: Async MongoDB Chat History (non-blocking)

- Added background persistence of chat inputs to MongoDB collection `chat_history` from the Redis chat endpoint.
- Uses FastAPI `BackgroundTasks` to schedule insert after Redis `RPUSH`, ensuring no impact on live chat latency.
- Inserted document reuses the same normalized payload saved to Redis and adds `redis_key` context.
- Errors during MongoDB background insert are logged but do not affect the Redis success response.

### Web UI: Ollama assistant response persisted to Redis

- Next.js API route `/api/ollama` now accepts `{ message, chatId, userId, philosopher }`.
- After successful generation from the local Ollama server, the route fire-and-forget pushes an `assistant_message` entry to FastAPI Redis endpoint:
  - Shape: `{ type: 'assistant_message', text, model, source: 'ollama', original, context }`
  - Stored in same list as user messages: `chat:{user_id}:{chat_id}:messages`.
- Does not block UI response; logs warnings on push failures.

### Files Changed
- `backend/routers/chat.py` ‚Äî schedules background MongoDB insert in `push_chat_message_to_redis()`.
- `backend/database.py` ‚Äî registered `chat_history` in `DatabaseManager` collections.

### Verification (PowerShell)
```powershell
$u = 'analytics206@gmail'
$c = [guid]::NewGuid().ToString()
$payload = @{ type='user_message'; text='Hello from web-ui'; state=@{ step='start' } } | ConvertTo-Json -Depth 5
$enc = [System.Web.HttpUtility]::UrlEncode($payload)
Invoke-RestMethod -Method Post -Uri "http://localhost:8000/api/v1/chat/redis/$($u)/$($c)?input=$enc"
Invoke-RestMethod -Method Get  -Uri "http://localhost:8000/api/v1/chat/redis/$($u)/$($c)"
```
Expect Redis to contain the normalized item. MongoDB will contain the same payload in `chat_history` shortly after the POST.

## Version 0.3.4 (August 16, 2025)

### Backend: Redis Chat Message Normalization

- Ensured every stored Redis chat item includes `user_id` and `chat_id`.
- JSON payloads sent via `input` are parsed and normalized:
  - Elevates common fields to top-level when present: `type`, `text`, `state`.
  - Preserves the original parsed payload under `original` for traceability.
  - If `input` is plain text, it is stored under `message`.
- Applies to POST endpoint `POST /api/v1/chat/redis/{user_id}/{chat_id}?input=<STRING>&ttl_seconds=<INT>` in `backend/routers/chat.py`.

### Documentation

- Updated `docs/06-system_design.md` to reflect normalized Redis message shape.

### Verification (PowerShell)

- After sending a new message from the web UI:
  - `$u='analytics206@gmail'`
  - `$c='<new_chat_id_from_browser>'`
  - `Invoke-RestMethod -Method Get -Uri "http://localhost:8000/api/v1/chat/redis/$($u)/$($c)"`
- Expect items with top-level `user_id`, `chat_id`, and elevated `type`/`text`/`state` plus `original`.

## Version 0.3.3 (August 15, 2025)

### Redis Chat Session State and UI Integration

- Web UI chat now manages session state: `userId`, `chatId`, `date`, `startTime`, `endTime`.
- On mount: generates `chatId`, sends `session_start` to backend Redis endpoint.
- On each send: pushes `user_message`.
- On unmount: sends `session_end`.
- Backend: added FastAPI endpoints to push and fetch messages in Redis lists:
  - POST `/api/v1/chat/redis/{user_id}/{chat_id}?input=<STRING>&ttl_seconds=<INT>`
  - GET `/api/v1/chat/redis/{user_id}/{chat_id}`
- Data stored as JSON strings per item with `message`, `timestamp` (UTC ISO), `date`.
- Uses `NEXT_PUBLIC_BACKEND_API_URL` for web UI ‚Üí backend base URL.
- No auth changes; placeholder `userId='analytics206@gmail'` until login is wired.

### Files Changed
- `backend/routers/chat.py` ‚Äî Redis endpoints added.
- `requirements.txt` ‚Äî added `redis>=5.0.0`.
- `web-ui/src/components/chat/chat-interface.tsx` ‚Äî session state + Redis integration.
- `docs/06-system_design.md` ‚Äî added Redis session architecture.
- `docs/07-tech_stack.md` ‚Äî documented Redis in Messaging System.

### Verification (PowerShell)
- In browser, open `/chat`; copy `ChatID` from console log.
- `$u='analytics206@gmail'`
- `$c='<paste_chat_id>'`
- `Invoke-RestMethod -Method Get -Uri "http://localhost:8000/api/v1/chat/redis/$($u)/$($c)"`
- Expect `session_start` first, `user_message` entries after sending input, and `session_end` after leaving the page.

### Notes
- Redis config in `config/default.yaml` (`host`, `port`, `password`, `db`).
- Data retention optional via `ttl_seconds` query param on POST.

## Version 0.3.2 (August 15, 2025)

### Web-UI: Ollama Chat Integration

- Added a new server-side API proxy at `web-ui/src/app/api/ollama/route.ts` to forward chat prompts to a local Ollama server.
  - Supports environment variables: `OLLAMA_BASE_URL` and `OLLAMA_MODEL`.
  - Backward/legacy compatibility: `OLLAMA_API_URL` + `OLLAMA_API_PORT` are also supported when `OLLAMA_BASE_URL` is not set.
  - Normalizes Ollama responses to `{ response }` to match existing `ChatInterface` expectations.
  - Uses non-streaming mode (`stream: false`) for initial implementation.

### Web-UI: New Chat Page

- Added a simple chat page at `web-ui/src/app/chat/page.tsx` that reuses `ChatInterface` with `endpoint="/api/ollama"`.
- Maintains styling consistency with existing components and Tailwind theme.
- Intended for quick local testing with Ollama models (default: `llama3:latest`).

### Landing Page UX

- Updated `web-ui/src/components/sections/hero-section.tsx` "Start Exploring" button to open `/chat` in a new tab using the `Button` component's `asChild` prop.

### Configuration

- Updated `web-ui/.env.example` with Ollama variables:
  - `OLLAMA_BASE_URL` (default `http://localhost:11434`)
  - `OLLAMA_MODEL` (default `llama3:latest`)
  - Optional legacy variables: `OLLAMA_API_URL`, `OLLAMA_API_PORT`

### Files Changed

- `web-ui/src/app/api/ollama/route.ts`
- `web-ui/src/app/chat/page.tsx`
- `web-ui/src/components/sections/hero-section.tsx`
- `web-ui/.env.example`

### Verification

- Basic web-ui chat confirmed working locally. Next.js dev server auto-selected fallback port `3002` (port 3000 was in use): `http://localhost:3002`.
- `/chat` route loads and sends messages successfully via `/api/ollama` proxy to the local Ollama server.
- Default model used: `OLLAMA_MODEL=llama3:latest` (configurable via environment variables).
- See `web-ui/README_chat.md` for quick-start steps and PowerShell API test commands.

## Version 0.3.1 (August 12, 2025)

### Orchestrator: Discussion Hooks Join Fix

- Ensured author-specific join for `discussion_hook` in `chat_orchestrator/master_combiner.js`.
- Fetches via `/api/v1/summaries/discussion-hooks` using:
  - `topic={full author}` and `topic={last name}`; merges and de-duplicates results.
  - Fallback: unfiltered fetch, then strict client-side filtering by author terms.
- Flattens documents that contain nested `discussion_hooks` into hook items; supports:
  - Array and object forms (e.g., `{ author: "Plato", discussion_hooks: [...] }` or `discussion_hooks: { ... }`).
- Prevents the entire global dataset from being attached to every philosopher.
- Robust matching (word-boundary + substring) across `topic`, `content`, `themes`, and optional `author`/`philosopher` fields.

### Orchestrator: Master Aggregation & Joins

- Implemented full per-author aggregation pipeline in `chat_orchestrator/master_combiner.js` with Redis outputs and optional JSON dumps.
- Join rules:
  - Philosophers base: `GET /api/v1/philosophers?limit=1000` (with optional `is_active_chat=1` for active set).
  - Philosophy school join: `GET /api/v1/philosophy-schools?limit=1000` and map by `philosophers.school_id` ‚Üí `school`.
  - By-author aggregator: `GET /api/v1/philosophers/by-author/{author}` used as primary per-author payload (aphorisms, book_summary, idea_summary, top_10_ideas, philosophy_themes, philosopher_summary).
  - Bibliography: `GET /api/v1/books/bibliography/by-author/{author}` (normalize single-object ‚Üí array).
  - Conversation logic: `GET /api/v1/chat/conversation-logic?author={author}`.
  - Discussion hooks: `GET /api/v1/summaries/discussion-hooks` with author-focused queries and strict client-side filtering (see section above).
  - Persona core: `GET /api/v1/chat/persona-cores?philosopher={author}`.
  - Modern adaptation: `GET /api/v1/chat/modern-adaptations?philosopher={author}`.
  - Chat blueprints: `GET /api/v1/chat/blueprints` fetched once and applied to all philosophers (global dataset).

### Normalization & Data Shape

- `normalizeByAuthorData()` ensures array shape for all collections and aliases `top_ten_ideas` ‚Üí `top_10_ideas`.
- Bibliography normalization wraps single docs into arrays to prevent empty joins.
- `combineOne()` merges per-author collections, adds `school`, attaches global `chat_blueprints`, and computes `counts` for all collections.
- `discussion_hook` is flattened and de-duplicated before join; others are attached as returned.

### Collections Covered (per author unless noted)

- Philosophers (base list driving aggregation)
- Aphorisms
- Book Summary
- Bibliography (normalized single-document to array)
- Conversation Logic
- Discussion Hook (author-filtered and flattened)
- Idea Summary
- Modern Adaptation
- Persona Core
- Philosopher Summary
- Philosophy Themes
- Top 10 Ideas (alias supported from top_ten_ideas)
- Philosophy School (joined by `school_id` from philosophers)
- Chat Blueprints (global, applied to each philosopher)

### Concurrency, Config, and Reliability

- Concurrency: Batched per-author work via `processWithConcurrency` with `ORCHESTRATOR_CONCURRENCY=6` default.
- Redis TTL: Controlled by `MASTER_ORCHESTRATOR_TTL` (seconds). `0` disables TTL.
- Environment & auth: Uses `FASTAPI_BASE_URL`, optional `FASTAPI_API_KEY` bearer header, `REDIS_URL`.
- Error handling: Defensive `.catch(() => [])/{}` on per-call fetches to avoid failing the entire aggregation.

### Behavior/Compatibility

- Output structure remains `discussion_hook: []` per philosopher.
- If no author-relevant hooks exist, the array may be empty (no global default join).
- No API contract changes; no endpoint changes.

### Verification

- Orchestrator run results:
  - Combined counts: `all=79`, `active=14`.
  - Stored Redis keys: `master_orchestrator`, `master_orchestrator_active`.
  - Optional JSON written with `--write-json`:
    - `/app/master_orchestrator.json`
    - `/app/master_orchestrator_active.json`

### Files Changed

- `chat_orchestrator/master_combiner.js`: fetching, filtering, flattening, and combine logic for `discussion_hook`.

### Next Steps

- Optional: theme-based matching as secondary fallback to improve recall while preserving author relevance.
- Add metrics/telemetry for per-author hook counts.

## Version 0.3.0 (August 6, 2025)

### Major Features

#### üî¥ Redis Cache Integration
- **Official Redis 7 Alpine** - Added Redis service using `redis:7-alpine` official Docker image
- **AOF Persistence** - Configured Append Only File (AOF) persistence for maximum data durability
- **Password Authentication** - Secured Redis with password authentication using environment variables
- **Persistent Storage** - Redis data persists in `./docker_volumes/redis_data` with proper volume mounting
- **Health Monitoring** - Comprehensive health checks using `redis-cli ping` with authentication
- **Port Configuration** - External port 6380 mapped to internal 6379 to avoid conflicts
- **Network Integration** - Connected to `daemonium-network` for inter-service communication

#### üü¢ Node.js 20 LTS Runtime
- **Official Node.js 20 LTS** - Added Node.js service using `node:20-alpine` official Docker image
- **Auto-Initialization** - Automatically creates `package.json` and basic Express.js server if not present
- **Redis Integration** - Pre-configured with `redis@^4.6` package and connection environment variables
- **Database Connectivity** - Pre-configured MongoDB connection with `mongoose@^7.0` package
- **Persistent Storage** - Three-tier storage system:
  - `nodejs_app` - Application code and files (`./docker_volumes/nodejs_app`)
  - `nodejs_modules` - Node.js dependencies (`./docker_volumes/nodejs_modules`)
  - `nodejs_cache` - NPM cache for faster builds (`./docker_volumes/nodejs_cache`)
- **Service Dependencies** - Waits for Redis and MongoDB to be healthy before starting
- **Health Monitoring** - Uses wget to monitor service availability on port 3000
- **Port Configuration** - External port 3001 mapped to internal 3000 to avoid conflicts with web-ui

#### üîß Docker Compose Enhancements
- **Volume Management** - Added four new persistent volumes following project naming conventions:
  - `daemonium_redis_data` - Redis data persistence
  - `daemonium_nodejs_app` - Node.js application files
  - `daemonium_nodejs_modules` - Node.js dependencies
  - `daemonium_nodejs_cache` - NPM cache storage
- **Service Orchestration** - Proper dependency management with health check conditions
- **Environment Variables** - Configurable passwords and connection strings using environment variables
- **Network Integration** - All new services connected to existing `daemonium-network`

### Technical Architecture Updates
- **Redis Cache Layer** - High-performance in-memory cache with AOF persistence for session management
- **JavaScript Runtime** - Node.js 20 LTS environment ready for real-time features and API integrations
- **Database Connectivity** - Pre-configured connections to Redis (caching) and MongoDB (data storage)
- **Microservices Ready** - Foundation for Node.js microservices and real-time chat features

### Connection Configuration
```bash
# Redis Connection (from Node.js containers)
REDIS_URL=redis://:ch@ng3m300@redis:6379

# Redis Connection (from host)
redis://:ch@ng3m300@localhost:6380

# MongoDB Connection (from Node.js containers)
MONGODB_URL=mongodb://admin:ch@ng3m300@mongodb:27017
```

### Usage Examples
```bash
# Start all services including new Redis and Node.js
docker compose up -d

# Check Redis connectivity
docker exec daemonium-redis redis-cli -a ch@ng3m300 ping

# Access Node.js service
curl http://localhost:3001

# View Node.js logs
docker logs daemonium-nodejs

# Connect to Node.js container
docker exec -it daemonium-nodejs sh
```

### Benefits
- ‚úÖ **High-Performance Caching** - Redis provides sub-millisecond response times for cached data
- ‚úÖ **Session Management** - Ready for user session storage and management
- ‚úÖ **Real-Time Features** - Node.js foundation for WebSocket connections and real-time chat
- ‚úÖ **API Integration** - Node.js environment ready for external API integrations
- ‚úÖ **Data Persistence** - All data survives container restarts and recreations
- ‚úÖ **Production Ready** - Proper health checks, authentication, and monitoring
- ‚úÖ **Scalable Architecture** - Foundation for microservices and horizontal scaling
- ‚úÖ **Development Friendly** - Auto-initialization reduces setup complexity

---
## Version 0.2.9 (August 6, 2025)

### Major Features

#### üîç Enhanced Ollama Validation Script
- **Comprehensive Model Loading Logic** - Enhanced `scripts/build_neo4j_metadata/validate_ollama.py` with proper model loading and warmup timeouts
- **Centralized Configuration Integration** - Full integration with `config/ollama_models.yaml` for model assignments, timeouts, and server settings
- **Smart Fallback Testing** - Implements proper fallback strategy: test default model first, only test alternatives if default fails, stop at first passing alternative
- **Progressive Model Loading** - Added `wait_for_model_loading()` method with progressive wait intervals [5, 10, 15, 20, 30] seconds
- **Model Responsiveness Testing** - Quick 5-second tests to verify model availability before full validation
- **Enhanced Timeout Management** - Uses config-driven timeouts:
  - **Model-specific timeouts**: DeepSeek-R1 (160s), Llama3.2 (120s), Granite-Embedding (120s)
  - **Task-type defaults**: All tasks now use 160s timeout for reliability
  - **Model loading timeouts**: 160s for normal loading, 160s for initial warmup
  - **Pull timeouts**: Calculated as model timeout √ó 3 (minimum 5 minutes)

#### üìä Comprehensive Validation Reporting
- **Detailed Console Logging** - Enhanced logging with timeout information, response times, command outputs, and partial response previews
- **Dual Report Generation** - Generates both text and JSON reports in `scripts/build_neo4j_metadata/reports/`
- **Report Contents**:
  - Execution details (start/end times, duration, config paths)
  - Server status and response times
  - Task validation summary (which model passed per task)
  - Detailed model results (generation/embeddings test results)
  - Configuration details (timeouts, alternatives, server URLs)
  - Overall validation status (success/partial/failure)
- **Developer-Friendly Output** - Verbose logging designed for analyst review with command lines, endpoints, and timing information

#### ‚öôÔ∏è Configuration Enhancements
- **Missing Config Method** - Added `get_alternatives_for_task()` method to `config/ollama_config.py`
- **Model Loading Configuration** - Enhanced config loader with model loading settings access
- **Timeout Hierarchy** - Proper fallback chain: model-specific ‚Üí task-default ‚Üí global fallback
- **Environment Variable Support** - Maintains support for `OLLAMA_MODEL_*` environment variable overrides

#### üéØ Validation Logic Improvements
- **Smart Model Testing** - Tracks tested models to avoid redundant loading waits
- **First Model Warmup** - Extended wait time for initial model startup (160s)
- **Model Switching Logic** - Proper delays between different model tests
- **Automatic Model Pulling** - Downloads missing models with appropriate timeouts
- **Generation and Embeddings Testing** - Comprehensive functionality testing for all model types

### Usage Examples
```bash
# Basic validation with detailed output
python scripts/build_neo4j_metadata/validate_ollama.py --verbose

# Custom config file
python scripts/build_neo4j_metadata/validate_ollama.py --config /path/to/config.yaml

# Check generated reports
ls scripts/build_neo4j_metadata/reports/ollama_validation_*.txt
ls scripts/build_neo4j_metadata/reports/ollama_validation_*.json
```

### Benefits
- ‚úÖ **Reliable Model Validation** - Proper loading timeouts prevent false negatives
- ‚úÖ **Production Ready** - Comprehensive error handling and detailed reporting
- ‚úÖ **Configuration Consistency** - Uses same config system as enhanced Neo4j knowledge graph builder
- ‚úÖ **Developer Insights** - Detailed logs and reports for troubleshooting and analysis
- ‚úÖ **Automated Workflow** - Can be integrated into CI/CD pipelines for Ollama environment validation
- ‚úÖ **Timeout Reliability** - Increased timeouts (160s) ensure stable validation on slower systems

---
## Version 0.2.8 (July 31, 2025)

### Major Features

#### üöÄ FastAPI Backend for MongoDB
- **Complete REST API** - Created comprehensive FastAPI backend in `backend/` folder for philosopher chatbot frontend
- **30+ API Endpoints** - Full CRUD operations across all MongoDB collections:
  - **Philosophers** - Search, filtering, related philosophers discovery
  - **Books** - Full text access, summaries, author filtering, chapter navigation
  - **Aphorisms** - Random selection, philosopher/theme filtering
  - **Ideas** - Top ten philosophical concepts, idea summaries
  - **Summaries** - Philosophy themes, modern adaptations, discussion hooks
  - **Chat** - Mock chatbot endpoints, personality profiles, conversation starters
  - **Search** - Global search, suggestions, collection-specific queries
- **Docker Integration** - Fully containerized with proper health checks and networking
- **Interactive Documentation** - Automatic Swagger UI at `/docs` and ReDoc at `/redoc`
- **Async MongoDB Integration** - High-performance async operations using Motor driver
- **Pydantic v2 Models** - Complete data validation and serialization
- **CORS Support** - Ready for frontend integration with configurable origins
- **Comprehensive Error Handling** - Detailed error responses and logging
- **Health Monitoring** - Database connection monitoring and API statistics

#### üèóÔ∏è Backend Architecture
- **FastAPI 0.116.1** - Modern Python web framework with automatic API documentation
- **Motor 3.7.1** - Async MongoDB driver for high-performance database operations
- **Pydantic 2.5.0** - Data validation with pydantic-settings for configuration management
- **Docker Containerization** - Python 3.11-slim base image with optimized build process
- **Modular Router Design** - Organized endpoints across multiple router modules
- **Configuration Management** - YAML-based config with Docker environment overrides
- **Database Connection Pooling** - Efficient MongoDB connection management
- **API Versioning** - Structured `/api/v1/` endpoint organization

---
## Version 0.2.7 (July 31, 2025)

### Major Features

#### üìÑ Document Reader MCP Server
- **New MCP Server** - Created `scripts/mcp_document_reader.py` for reading and analyzing markdown and text files within Windsurf IDE
- **Four Comprehensive Tools**:
  - **`read_document`** - Read complete file content with metadata (encoding, size, line count)
  - **`list_documents`** - List all supported documents in directories with recursive search
  - **`get_document_info`** - Get file metadata without reading content (size, modification date)
  - **`get_supported_extensions`** - List all supported file types
- **Multi-Encoding Support** - Automatic encoding detection with fallback support (UTF-8, UTF-8-BOM, Latin-1, CP1252)
- **File Size Protection** - Configurable maximum file size limits (default 1MB) to prevent memory issues
- **Cross-Platform Compatibility** - Works on Windows, Linux, and macOS with proper path handling
- **No Dependencies** - Uses only Python standard library for maximum compatibility
- **Comprehensive Error Handling** - Graceful error handling with detailed error messages

#### üîå Enhanced MCP Integration
- **Windsurf IDE Configuration** - Added Document Reader MCP to user's `mcp_config.json` configuration
- **Complete Documentation** - Updated main README.md with comprehensive MCP servers section
- **Standalone Setup Guide** - Created `README_DOCREADER.md` following the same structure as `README_TTS.md`
- **Natural Language Interface** - Users can interact with document tools through conversational commands
- **Testing Framework** - Command-line testing procedures and verification methods

#### üìö Supported File Types
- **Markdown Files** - `.md`, `.markdown` extensions
- **Text Files** - `.txt`, `.text` extensions
- **Encoding Flexibility** - Automatic detection and conversion of various text encodings
- **Metadata Extraction** - File size, line count, modification dates, and path information

#### üîç Qdrant Vector Database Integration
- **Comprehensive Uploader** - Created `scripts/build_qdrant_metadata/upload_mongodb_to_qdrant.py` for MongoDB to Qdrant data migration
- **High-Quality Embeddings** - Uses sentence-transformers (all-mpnet-base-v2) for 768-dimensional vector embeddings
- **Multiple Collection Support** - Processes 5 MongoDB collections with specialized text extraction:
  - `book_summaries` - Detailed summaries of philosophical works
  - `aphorisms` - Philosophical aphorisms and quotes
  - `idea_summaries` - Individual philosophical concept summaries
  - `philosopher_summaries` - Comprehensive philosopher overviews
  - `top_ten_ideas` - Top 10 philosophical ideas and concepts
- **Batch Processing** - Efficient 50-document batches with comprehensive error handling
- **Automatic Collection Creation** - COSINE distance similarity with proper vector configuration
- **Unique Point IDs** - MD5 hashing for consistent point identification across uploads
- **Text Preprocessing** - Automatic truncation and cleaning for embedding model token limits
- **Configuration Integration** - Reads from `config/default.yaml` with automatic MongoDB URL encoding
- **Testing Framework** - Includes `test_qdrant_connection.py` and `simple_test.py` for validation

#### üîß Qdrant Dependencies and Setup
- **New Dependencies** - Added `qdrant-client>=1.7.0` and `sentence-transformers>=2.2.2` to requirements.txt
- **Port Configuration** - Qdrant REST API (port 6343) and GRPC (port 6344) support
- **Docker Integration** - Works seamlessly with existing Docker Compose Qdrant service
- **Error Resilience** - Comprehensive error handling and logging for production use

### Usage Examples
```bash
# Document Reader MCP - In Windsurf IDE chat, users can now use:
"Please read the contents of README.md"
"List all markdown files in this project"
"What file types does the document reader support?"
"Show me information about the config file"
"List all text files in the docs directory"

# Document Reader MCP - Command-line testing:
echo '{"jsonrpc":"2.0","id":1,"method":"tools/list"}' | python scripts/mcp_document_reader.py

# Qdrant Vector Database - Upload and test:
python scripts/build_qdrant_metadata/upload_mongodb_to_qdrant.py
python scripts/build_qdrant_metadata/test_qdrant_connection.py
python scripts/build_qdrant_metadata/simple_test.py
```

### Benefits

#### Document Reader MCP Benefits:
- ‚úÖ **Local File Access** - Direct access to project documentation and configuration files
- ‚úÖ **No API Keys Required** - Completely free with no external service dependencies
- ‚úÖ **Offline Operation** - Works entirely offline with local file system access
- ‚úÖ **Privacy Focused** - No external data transmission or cloud service requirements
- ‚úÖ **Developer Productivity** - Quick access to project files without leaving the IDE chat
- ‚úÖ **Documentation Analysis** - Easy analysis and summarization of project documentation
- ‚úÖ **Configuration Review** - Quick review of configuration files and settings

#### Qdrant Vector Database Benefits:
- üîç **Semantic Search** - Find philosophically related content across all MongoDB collections
- üéØ **RAG Integration** - Enable retrieval-augmented generation for enhanced chatbot responses
- ‚ö° **High Performance** - Optimized vector similarity search with COSINE distance metrics
- üîÑ **Batch Processing** - Efficient handling of large philosophical text collections
- üõ°Ô∏è **Error Resilience** - Comprehensive error handling and logging for production use
- üìä **Metadata Preservation** - Maintains original document structure and metadata
- üîß **Production Ready** - Successfully connects to both MongoDB and Qdrant with proper configuration

### Documentation
- **Main README Integration** - Added comprehensive "üîå MCP Servers" section to main README.md
- **Standalone Guide** - Created `README_DOCREADER.md` with complete setup and usage instructions
- **Configuration Examples** - JSON configuration examples for Windsurf IDE setup
- **Troubleshooting Guide** - Common issues and solutions for MCP server setup
- **Quick Test Commands** - Ready-to-use test commands for immediate verification

---
## Version 0.2.6 (July 30, 2025)

### Major Features

#### üîç Ollama Embedding Model Evaluation System
- **Comprehensive Model Evaluation** - Added `llm_evaluation/` toolkit for evaluating Ollama embedding models on knowledge graph construction tasks
- **Philosophy-Focused Test Datasets** - Created specialized test data for philosophical content evaluation:
  - **Semantic Similarity**: 15 Nietzschean concept pairs with expected similarity scores
  - **Entity Recognition**: 8 philosophical texts with labeled entities (PHILOSOPHER, CONCEPT, WORK)
  - **Relation Extraction**: 10 texts with philosophical relation triplets
  - **Clustering**: 8 concept clusters for philosophical themes
- **Multi-Model Comparison** - Simultaneous evaluation of 6 Ollama embedding models:
  - `nomic-embed-text` - Nomic's high-quality text embedding model
  - `mxbai-embed-large` - MixedBread AI's large embedding model
  - `all-minilm` - MiniLM embedding model
  - `snowflake-arctic-embed` - Snowflake's Arctic embedding model
  - `all-MiniLM-L6-v2` - Compact MiniLM variant
  - `llama3.1:latest` - Llama 3.1 with embedding capabilities
- **Specialized KG Metrics** - Research-based evaluation metrics for knowledge graph tasks:
  - **Semantic Similarity**: Accuracy, correlation, and mean absolute error
  - **Clustering Quality**: Silhouette score, coherence, and separation
  - **Entity Recognition**: Entity clustering and entity-text similarity
  - **Knowledge Graph Structure**: Relation coherence, graph density, clustering coefficient
  - **Embedding Quality**: Pairwise similarity, variance, and norm distribution
- **Automated Setup** - `setup_ollama_models.py` script for automatic model installation and verification
- **Comprehensive Reporting** - JSON results and detailed comparative analysis with model rankings

#### Migration from Hugging Face to Ollama
- **Local-First Architecture** - Completely migrated from Hugging Face to Ollama for all embedding generation
- **Consistent Infrastructure** - Uses same Ollama setup as existing knowledge graph builders
- **Reduced Dependencies** - Eliminated heavy PyTorch and Hugging Face dependencies
- **Better Performance** - Direct API calls to local Ollama service for faster processing

### Usage Examples
```bash
# Setup required Ollama models
python llm_evaluation/setup_ollama_models.py

# Evaluate all embedding models
python llm_evaluation/main_sentence_transformers.py

# Evaluate single model
python -c "from llm_evaluation.evaluation.evaluate_sentence_transformers import evaluate_sentence_transformer_model; evaluate_sentence_transformer_model('nomic-embed-text')"
```

### Benefits
- ‚úÖ **Model Selection** - Data-driven selection of optimal embedding models for philosophical content
- ‚úÖ **Quality Assurance** - Comprehensive evaluation across multiple KG construction tasks
- ‚úÖ **Local Control** - All processing done locally through Ollama without external dependencies
- ‚úÖ **Philosophy-Optimized** - Test datasets specifically designed for philosophical knowledge graphs
- ‚úÖ **Automated Workflow** - Simple setup and evaluation process with detailed reporting
- ‚úÖ **Integration Ready** - Results can be directly applied to existing Neo4j knowledge graph builders

### Documentation
- **Comprehensive Guide** - Detailed documentation in `llm_evaluation/README.md`
- **Main README Integration** - Added embedding evaluation section to main project README
- **Setup Instructions** - Complete installation and usage instructions for Ollama models

---
## Version 0.2.5 (July 30, 2025)

### Major Features

#### Knowledge Graph Quality Evaluation System
- **Comprehensive Evaluation Framework** - Added `scripts/build_neo4j_metadata/evaluate_knowledge_graphs.py` for research-based knowledge graph quality assessment
- **Multi-Database Comparison** - Support for comparing multiple Neo4j databases simultaneously with side-by-side analysis
- **Research-Based Metrics** - Implemented quality dimensions based on academic research:
  - **Structural Metrics**: Graph density, clustering coefficient, degree distribution
  - **Completeness Metrics**: Schema coverage, property completeness, linkability
  - **Consistency Metrics**: Temporal and semantic coherence
  - **Chatbot-Specific Metrics**: AI enhancement ratio, content accessibility, philosophical domain coverage
- **Multiple Report Formats** - Generate comprehensive reports in multiple formats:
  - Terminal output with formatted statistics
  - JSON reports for machine-readable data
  - Text reports with detailed analysis and actionable recommendations
  - Visual PDF reports with charts, graphs, and comparison dashboards
- **Professional Visualizations** - Advanced charts including bar charts, pie charts, and quality dimension comparisons
- **Organized Output Management** - All reports automatically saved to `scripts/build_neo4j_metadata/reports/` directory

#### Enhanced Dependencies
- **Visualization Libraries** - Added matplotlib, seaborn, and Pillow for advanced chart generation
- **GPU Support** - Automatic CUDA detection for faster semantic similarity calculations
- **Report Generation** - Professional PDF generation with multi-page layouts and statistical visualizations

### Usage Examples
```bash
# Evaluate single database with all reports
python scripts/build_neo4j_metadata/evaluate_knowledge_graphs.py --databases daemonium-primary --all-reports

# Compare multiple databases
python scripts/build_neo4j_metadata/evaluate_knowledge_graphs.py --databases daemonium-primary daemonium-comparison --compare --all-reports

# Generate specific report types
python scripts/build_neo4j_metadata/evaluate_knowledge_graphs.py --databases daemonium-primary --text-report
python scripts/build_neo4j_metadata/evaluate_knowledge_graphs.py --databases daemonium-primary --visual-report
```

### Benefits
- ‚úÖ **Quality Assurance** - Comprehensive evaluation of knowledge graph quality for chatbot applications
- ‚úÖ **Actionable Insights** - Specific recommendations for improving graph structure and content
- ‚úÖ **Comparative Analysis** - Easy A/B testing between different knowledge graph versions
- ‚úÖ **Professional Reporting** - Publication-ready charts and detailed analysis reports
- ‚úÖ **Research-Based** - Metrics grounded in academic knowledge graph evaluation literature

---
## Version 0.2.4 (July 29, 2025)

### Major Features

#### Neo4j Enterprise Edition Multi-Database Support
- **Enterprise Edition Upgrade** - Upgraded from Neo4j Community Edition to Enterprise Edition for advanced multi-database capabilities
- **Multiple Database Architecture** - Created three separate databases for comparison and experimental work:
  - `daemonium-primary` - Primary knowledge graph
  - `daemonium-comparison` - Comparison knowledge graph
  - `daemonium-experimental` - Experimental features
- **Free Development License** - Leverages Neo4j Enterprise Edition's free development license for local use

#### Database Management System
- **Database Management Script** - Added `scripts/manage_neo4j_databases.py` for comprehensive database administration
- **Database Utility Library** - Created `scripts/utils/neo4j_database_utils.py` for consistent database selection across all scripts
- **Automated Database Creation** - Scripts automatically create databases if they don't exist
- **Database Statistics and Monitoring** - Built-in tools for monitoring database health and content statistics

#### Flexible Database Selection
- **Multiple Selection Methods** - Support for database selection via:
  - Command-line arguments: `python script.py daemonium-primary`
  - Environment variables: `NEO4J_TARGET_DATABASE=daemonium-comparison`
  - Script-specific mappings in configuration
  - Default database fallback
- **Enhanced Knowledge Graph Builder** - Updated `enhanced_neo4j_kg_build.py` to support target database selection
- **Centralized Configuration** - All database settings managed through `config/default.yaml`

### Database Management Commands

#### Setup and Administration
```bash
# Create all configured databases
python scripts/manage_neo4j_databases.py setup

# List all databases with status
python scripts/manage_neo4j_databases.py list

# Show database statistics
python scripts/manage_neo4j_databases.py stats daemonium-primary

# Clear database content (use with caution)
python scripts/manage_neo4j_databases.py clear daemonium-experimental
```

#### Knowledge Graph Building
```bash
# Build knowledge graph in default database
python scripts/build_neo4j_metadata/enhanced_neo4j_kg_build.py

# Build knowledge graph in specific database
python scripts/build_neo4j_metadata/enhanced_neo4j_kg_build.py daemonium-primary
python scripts/build_neo4j_metadata/enhanced_neo4j_kg_build.py daemonium-comparison

# Use environment variable for database selection
NEO4J_TARGET_DATABASE=daemonium-experimental python scripts/build_neo4j_metadata/enhanced_neo4j_kg_build.py
```

### Technical Improvements
- **Docker Compose Updates** - Modified Neo4j service to use Enterprise Edition with proper license acceptance
- **Configuration Schema** - Enhanced `config/default.yaml` with database definitions and script mappings
- **Error Handling** - Robust error handling for database creation and connection failures
- **Database Naming Compliance** - Ensured all database names comply with Neo4j naming restrictions (hyphens instead of underscores)

### Benefits for Comparison Workflows
- **True Data Isolation** - Complete separation between different knowledge graph versions
- **Easy A/B Testing** - Compare different data processing approaches across databases
- **Experimental Safety** - Test new features in isolated experimental database
- **Version Control** - Maintain multiple versions of knowledge graphs simultaneously

---
## Version 0.2.3 (July 29, 2025)

### New Features

#### Bibliography Data Management
- **Bibliography Uploader Script** - Added `upload_bibliography_to_mongodb.py` for uploading author bibliography data to MongoDB
- **Flexible JSON Structure Support** - Script handles various root keys (e.g., `nietzsche_bibliography`, `plato_bibliography`, `author_bibliography`) for backward compatibility
- **Enhanced Bibliography Schema** - Added support for new `background` field in bibliography JSON structure
- **Author-Based Document IDs** - Creates unique document identifiers based on author names for consistent data management
- **Comprehensive Field Mapping** - Extracts and maps all bibliography fields including works, chronological periods, themes, and influence data

#### Master Uploader Integration
- **Updated Script Execution Order** - Added bibliography uploader to `run_all_uploaders.py` execution sequence
- **Strategic Positioning** - Bibliography data loads after core philosopher data but before detailed content for optimal dependency management

#### Data Structure Enhancements
- **Template Updates** - Enhanced bibliography template with new background field for richer author context
- **Modern Adaptation Support** - Added support for modern philosophical adaptations with new JSON structure
- **Philosopher Bio Template Refinements** - Streamlined template structure for better usability

### Technical Improvements
- **Robust Error Handling** - Enhanced error messages for missing or malformed bibliography keys
- **Backward Compatibility** - Maintains support for existing JSON files with different naming conventions
- **Metadata Preservation** - Stores original JSON key names for reference and debugging
- **Clean Document IDs** - Improved ID generation with better character handling (spaces, hyphens, periods)

### Configuration and Integration
- **MongoDB Collection Management** - Uses dedicated `bibliography` collection for author bibliography data
- **YAML Configuration Integration** - Leverages existing configuration system for database connections
- **Logging and Statistics** - Comprehensive logging with detailed upload statistics and error reporting

---
## Version 0.2.2 (July 27, 2025)

### New Features

#### Complete MongoDB Data Upload Suite
- **13 Specialized Uploader Scripts** - Comprehensive collection of MongoDB uploader scripts for all JSON data categories
- **Chat Blueprint Uploader** - Added `upload_chat_blueprints_to_mongodb.py` for chat blueprint templates and response pipelines
- **Conversation Logic Uploader** - Added `upload_conversation_logic_to_mongodb.py` for conversation strategies and tone selection
- **Discussion Hook Uploader** - Added `upload_discussion_hooks_to_mongodb.py` for categorized discussion prompts
- **Idea Summary Uploader** - Added `upload_idea_summaries_to_mongodb.py` for detailed philosophical idea analysis
- **Modern Adaptation Uploader** - Added `upload_modern_adaptations_to_mongodb.py` for contemporary philosophical applications
- **Persona Core Uploader** - Added `upload_persona_cores_to_mongodb.py` for philosopher persona definitions
- **Philosopher Bio Uploader** - Added `upload_philosopher_bios_to_mongodb.py` for biographical information
- **Philosopher Bot Uploader** - Added `upload_philosopher_bots_to_mongodb.py` for bot persona configurations
- **Philosopher Summary Uploader** - Added `upload_philosopher_summaries_to_mongodb.py` for comprehensive philosophical overviews
- **Philosophy Themes Uploader** - Added `upload_philosophy_themes_to_mongodb.py` for core philosophical themes and discussion frameworks
- **Top 10 Ideas Uploader** - Added `upload_top_10_ideas_to_mongodb.py` for ranked philosophical concepts

#### Universal Features Across All Uploaders
- **Template File Filtering** - All scripts automatically skip template files (files starting with 'template')
- **Document Merging** - Intelligent merge functionality that updates existing documents while preserving original upload timestamps
- **Comprehensive Logging** - Detailed logging with separate log files for each uploader script
- **Error Handling** - Robust error handling for connection failures, invalid JSON, and file system issues
- **Statistics Reporting** - Detailed upload statistics including processed, uploaded, updated, skipped, and error counts
- **Unique Document IDs** - Each uploader creates unique document identifiers based on content-specific fields
- **Metadata Tracking** - Rich metadata including content metrics, upload timestamps, and source file information

#### Configuration and Security
- **YAML Configuration Integration** - All scripts use `config/default.yaml` for MongoDB connection settings
- **URL Encoding** - Proper URL encoding of MongoDB credentials to handle special characters
- **Authentication Support** - Support for MongoDB authentication with admin database auth source
- **Modular Architecture** - Each uploader is self-contained with specialized document preparation logic

#### Documentation
- **Comprehensive Uploader Documentation** - Updated `README_uploaders.md` with all 13 uploader scripts, usage instructions, and troubleshooting
- **Dependencies** - Updated requirements with `pymongo>=4.6.0` and `PyYAML>=6.0.1`
- **Collection Mapping** - Clear documentation of which script uploads to which MongoDB collection

---

## Version 0.2.1 (July 27, 2025)

### New Features

#### MongoDB Data Upload Scripts (Initial Implementation)
- **Aphorism Uploader** - Added `upload_aphorisms_to_mongodb.py` script to upload JSON files from `json_bot_docs/aphorisms` to MongoDB `aphorisms` collection
- **Book Summary Uploader** - Added `upload_book_summaries_to_mongodb.py` script to upload JSON files from `json_bot_docs/book_summary` to MongoDB `book_summary` collection
- **Template File Filtering** - Both scripts automatically skip template files (files starting with 'template')
- **Document Merging** - Intelligent merge functionality that updates existing documents while preserving original upload timestamps
- **Comprehensive Logging** - Detailed logging with separate log files for each uploader script
- **Error Handling** - Robust error handling for connection failures, invalid JSON, and file system issues
- **Statistics Reporting** - Detailed upload statistics including processed, uploaded, updated, skipped, and error counts

#### Configuration and Security
- **YAML Configuration Integration** - Both scripts use `config/default.yaml` for MongoDB connection settings
- **URL Encoding** - Proper URL encoding of MongoDB credentials to handle special characters
- **Authentication Support** - Support for MongoDB authentication with admin database auth source

#### Documentation
- **Uploader Documentation** - Added comprehensive `README_uploaders.md` with usage instructions, troubleshooting, and development notes
- **Dependencies** - Updated requirements with `pymongo>=4.6.0` and `PyYAML>=6.0.1`

---

## Version 0.2.0 (May 3, 2025)

### Major Features

#### PDF Processing and Vector Storage
- **MongoDB Tracking System** - Added tracking of processed PDFs in `vector_processed_pdfs` collection to prevent duplicate processing
- **PDF Processing Tracking** - Each processed PDF is tracked with file hash, chunk count, and processing date
- **Category-Based Processing** - Implemented selective vector processing based on configured research categories
- **Papers per Category Limit** - Added configurable limit for papers to process per category

#### GPU Acceleration
- **GPU Support for Vector Operations** - Added GPU acceleration for both Qdrant vector database and embedding generation
- **Multi-GPU Support** - Implemented configurable GPU device selection for optimal performance
- **Automatic Device Detection** - Added graceful fallback to CPU when GPU is unavailable or not properly configured

#### Deployment Improvements
- **Hybrid Deployment Architecture** - Added support for running Qdrant locally with GPU while other services run in Docker
- **Host.Docker.Internal Integration** - Enhanced Docker services to communicate with local Qdrant instance
- **Standalone Qdrant Configuration** - Added documentation for running Qdrant with GPU acceleration
- **Docker Volume Path Handling** - Improved Windows path compatibility for mounted volumes

#### Error Handling
- **Ollama Integration Improvements** - Made Ollama optional with graceful fallback when not available
- **Better Error Recovery** - Added robust error handling for PDF processing failures

### Configuration Enhancements
- **Centralized PDF Directory Config** - Moved PDF directory configuration to central config file
- **Dynamic MongoDB Connection** - Improved connection handling to automatically adjust for local vs Docker environments
- **Ollama Configuration** - Added controls for enabling/disabling Ollama image analysis

### Documentation
- **Deployment Options** - Added documentation for both Docker and standalone deployment options
- **GPU Configuration Guide** - Documented GPU setup and acceleration options
- **Database Installation Guides** - Added detailed instructions for MongoDB, Neo4j, and Qdrant installation
- **Development Notes** - Added developer notes document for tracking ongoing work
- **Release Notes** - Added this release notes document

### Dependencies and Libraries
- **PyTorch with CUDA** - Updated PyTorch requirements to include CUDA support
- **Neo4j JavaScript Driver** - Added documentation for the JS driver required for the web UI

---

## Version 0.1.0 (April 26, 2025)

### Major Features

#### Data Ingestion and Storage
- **ArXiv API Integration** - Implemented paper ingestion from ArXiv Atom XML API
- **MongoDB Storage** - Created document storage for paper metadata with appropriate indexing
- **Neo4j Graph Database** - Established graph representation for papers, authors, and categories
- **PDF Downloading** - Added functionality to download and organize research papers in PDF format
- **Vector Embedding** - Implemented basic text vectorization using Hugging Face models
- **Qdrant Integration** - Set up vector similarity search with Qdrant database

#### Docker Containerization
- **Multi-Container Setup** - Built initial Docker Compose configuration for all services
- **Volume Persistence** - Implemented persistent storage for MongoDB and Neo4j data
- **Network Configuration** - Established internal container communication and port mapping
- **Service Orchestration** - Created coordinated startup/shutdown of all system components

#### Web Interface
- **Neo4j Visualization** - Created basic web interface for exploring the knowledge graph
- **Browsing Interface** - Implemented paper browsing and navigation features
- **Web UI Container** - Dockerized the web interface with appropriate connections to backend services

### Configuration Enhancements
- **YAML Configuration** - Created initial configuration file structure
- **Environment Variables** - Implemented environment variable support for container configuration
- **API Rate Limiting** - Added configurable rate limiting for ArXiv API access

### Documentation
- **Setup Instructions** - Created installation and setup documentation
- **README** - Established initial project documentation with overview and features
- **Configuration Guide** - Documented configuration options and their effects

### Dependencies and Libraries
- **MongoDB Python Driver** - Integrated PyMongo for database access
- **Neo4j Python Driver** - Added Neo4j connectivity for graph operations
- **Hugging Face Transformers** - Integrated for text embedding generation
- **Docker and Docker Compose** - Established containerization foundation
